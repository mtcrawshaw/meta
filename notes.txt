Todo:
Add PPO for single task
- Just get PPO running on CPU (make sure that PolicyNetwork.logstd is changing)
- Make tensor shapes consistent (extra dimension of length 1 or not?)
- Move to settings file
- Convert to package
- black/pylint/mypy
- Add GPU support
- Add multiprocessing
- Add recurrent policies?
Add MAML for single task distribution
Add modular meta learning for meta learning
Other baselines for meta learning?
Implement new ideas for meta learning
Implement learned loss convexity regularization for multi task learning

Settings to add:
- Network architecture hyperparameters
- Choice of optimizer and optimizer hyperparameters
- Parameter sharing between actor and critic
- Gradient clipping
- Advantage normalization?
- Value loss clipping?
