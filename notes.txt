Road map:
    PPO for single task
    Add MetaWorld support
--> Better evaluation
    Splitting networks for MTL
    PCGrad, sparse sharing, soft-layer ordering, other baselines for MTL
    Splitting networks for meta learning
    MAML and other baselines for meta learning
    Hyperparameter optimization
    Tests of statistical significance
    Learned loss convexity regularization for MTL

Current sprint:
    EMA of rewards instead of looking at past N
    Option to plot mean + std dev
    Evaluate success rate during training
    Plot success rate
    Saving settings, metrics under results
    Move legend outside of axes
    Add success rate computation for gym environments
--> Get tests to pass
    Metrics tests
    Evaluate metrics after training

Before merging to master:
- Use black, pylint, and mypy to clean up
- Make sure "pytest meta/" passes

Future additions:
- Test PPO for environments with action space Box((n1, n2))
- PPO training settings to add/consider:
    - Network architecture hyperparameters (more customized architectures)
    - Choice of optimizer and optimizer hyperparameters
    - Parameter sharing between actor and critic
    - Deterministic acting (i.e. always choose action with highest prob)
- Make tests deterministic
- Move tests outside of package
- Add feature so that task-index part of observation is not normalized

Possible additions:
- Optimize data transfer to GPU
- Different ways to collect data from multiple tasks. Cycle through tasks, randomly pick
  one, randomly pick one that is different from previous.
- Refactor RolloutStorage data generators. Put tensors into a dict. Can we just use good
  indexing to construct the batches instead of looping and stacking?
- Refactor naming in PPO implementation to clarify between episodes, rollouts, and
  trajectories

----------------------------------------------------------------------------------------

After finishing with running tests to show to Jana, we have some catching up to do:
- Figure out why addition of success rate has caused other tests to fail
- Get rid of stochasticity for MT10 + multi
- Write tests for metrics
